{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "pos_train_data = pd.read_csv('train_pos.tsv',sep = '\\t')\n",
    "neg_train_data = pd.read_csv('train_neg.tsv',sep = '\\t')\n",
    "pos_test_data = pd.read_csv('test_pos.tsv',sep = '\\t')\n",
    "neg_test_data = pd.read_csv('test_neg.tsv',sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pos_train_data = pos_train_data[['Text','Sentiment']]\n",
    "neg_train_data = neg_train_data[['Text','Sentiment']]\n",
    "pos_test_data = pos_test_data[['Text','Sentiment']]\n",
    "neg_test_data = neg_test_data[['Text','Sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Centered in the downtown and out skirts of Det...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The pilot of Enterprise has one thing that has...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The competition for the worst Warner Bros Kay ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I don't know much about Tobe Hooper, or why he...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Well, not yet, at least.&lt;br /&gt;&lt;br /&gt;It's not l...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Sentiment\n",
       "0  Centered in the downtown and out skirts of Det...          1\n",
       "1  The pilot of Enterprise has one thing that has...          1\n",
       "2  The competition for the worst Warner Bros Kay ...          0\n",
       "3  I don't know much about Tobe Hooper, or why he...          0\n",
       "4  Well, not yet, at least.<br /><br />It's not l...          0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train = pd.concat([pos_train_data,neg_train_data],ignore_index = True)\n",
    "data_train = data_train.sample(frac=1).reset_index(drop=True)\n",
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The world now seems to be in an odd stage of d...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>My yardstick for measuring a movie's watch-abi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>... So some people might argue that this can't...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Every time I watch this movie blood comes gush...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>John Leguizamo's one man shows are hit or miss...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Sentiment\n",
       "0  The world now seems to be in an odd stage of d...          0\n",
       "1  My yardstick for measuring a movie's watch-abi...          1\n",
       "2  ... So some people might argue that this can't...          0\n",
       "3  Every time I watch this movie blood comes gush...          0\n",
       "4  John Leguizamo's one man shows are hit or miss...          1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test = pd.concat([pos_test_data,neg_test_data],ignore_index = True)\n",
    "data_test = data_test.sample(frac=1).reset_index(drop=True)\n",
    "data_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "table = str.maketrans('', '', punctuation)\n",
    "\n",
    "def textclean(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [word for word in tokens if word.isalpha()]\n",
    "    tokens = [w.translate(table) for w in tokens]\n",
    "    tokens = [word for word in tokens if not word in stop_words]\n",
    "    tokens = [word for word in tokens if len(word) > 1]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['centered',\n",
       " 'downtown',\n",
       " 'skirts',\n",
       " 'detroit',\n",
       " 'comedy',\n",
       " 'found',\n",
       " 'terrific',\n",
       " 'new',\n",
       " 'comedic',\n",
       " 'duo',\n",
       " 'pat',\n",
       " 'morita',\n",
       " 'funny',\n",
       " 'man',\n",
       " 'happens',\n",
       " 'cop',\n",
       " 'japan',\n",
       " 'trail',\n",
       " 'industrial',\n",
       " 'secrets',\n",
       " 'thief',\n",
       " 'stolen',\n",
       " 'type',\n",
       " 'turbo',\n",
       " 'super',\n",
       " 'charger',\n",
       " 'reluctantly',\n",
       " 'goes',\n",
       " 'united',\n",
       " 'states',\n",
       " 'follow',\n",
       " 'thief',\n",
       " 'ordered',\n",
       " 'commander',\n",
       " 'pat',\n",
       " 'character',\n",
       " 'collides',\n",
       " 'leno',\n",
       " 'character',\n",
       " 'fast',\n",
       " 'talking',\n",
       " 'type',\n",
       " 'detroit',\n",
       " 'cop',\n",
       " 'cross',\n",
       " 'paths',\n",
       " 'though',\n",
       " 'honorable',\n",
       " 'japan',\n",
       " 'meet',\n",
       " 'old',\n",
       " 'school',\n",
       " 'detroit',\n",
       " 'police',\n",
       " 'investigative',\n",
       " 'two',\n",
       " 'stumble',\n",
       " 'trip',\n",
       " 'first',\n",
       " 'develop',\n",
       " 'turns',\n",
       " 'explosive',\n",
       " 'two',\n",
       " 'layered',\n",
       " 'powerhouse',\n",
       " 'team',\n",
       " 'solves',\n",
       " 'case',\n",
       " 'cold',\n",
       " 'battling',\n",
       " 'city',\n",
       " 'crime',\n",
       " 'boss',\n",
       " 'stolen',\n",
       " 'closing',\n",
       " 'case',\n",
       " 'two',\n",
       " 'go',\n",
       " 'despising',\n",
       " 'friends',\n",
       " 'working',\n",
       " 'well',\n",
       " 'together',\n",
       " 'little',\n",
       " 'worse',\n",
       " 'wear',\n",
       " 'need',\n",
       " 'top',\n",
       " 'manage',\n",
       " 'come',\n",
       " 'victorious',\n",
       " 'closing',\n",
       " 'rated',\n",
       " 'lewis',\n",
       " 'direction',\n",
       " 'makes',\n",
       " 'near',\n",
       " 'perfect',\n",
       " 'comedy',\n",
       " 'fun',\n",
       " 'ages',\n",
       " 'recommend',\n",
       " 'highly']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews = []\n",
    "\n",
    "for index,row in data_train.iterrows():\n",
    "    text = (row['Text'].lower())    \n",
    "    reviews.append(textclean(text))\n",
    "reviews[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models.doc2vec import \n",
    "\n",
    "d2v_reviews = []\n",
    "for i in range(len(reviews)):\n",
    "    d2v_reviews.append(TaggedDocument(words=reviews[i], tags=['REV_'+str(i)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TaggedDocument(words=['charming', 'even', 'begin', 'describe', 'saving', 'grace', 'absolutely', 'irresistible', 'anyone', 'ventures', 'movie', 'leave', 'spirits', 'soaring', 'high', 'haha', 'br', 'br', 'grace', 'trevethyn', 'brenda', 'blethyn', 'lost', 'husband', 'problems', 'get', 'whole', 'lot', 'worse', 'dearly', 'departed', 'left', 'money', 'outstanding', 'debts', 'faced', 'losing', 'everything', 'find', 'way', 'get', 'lot', 'cash', 'fast', 'gets', 'idea', 'gardener', 'matthew', 'craig', 'ferguson', 'asks', 'horticulturist', 'give', 'advice', 'plant', 'secretly', 'growing', 'grace', 'immediately', 'realizes', 'plant', 'marijuana', 'decide', 'use', 'gardening', 'skills', 'grow', 'lot', 'weed', 'sell', 'pay', 'outstanding', 'br', 'br', 'notable', 'quality', 'saving', 'grace', 'likability', 'every', 'character', 'extremely', 'sympathetic', 'save', 'first', 'minutes', 'film', 'good', 'cheer', 'everyone', 'wants', 'happy', 'ending', 'everyone', 'even', 'means', 'turning', 'blind', 'eye', 'rather', 'illegal', 'br', 'br', 'acting', 'brenda', 'blethyn', 'one', 'britain', 'finest', 'actresses', 'turns', 'could', 'caricature', 'fully', 'living', 'breathing', 'individual', 'nice', 'lady', 'stupid', 'craig', 'ferguson', 'equally', 'amiable', 'matthew', 'deadbeat', 'loser', 'likable', 'matter', 'rest', 'ensemble', 'cast', 'fits', 'category', 'well', 'special', 'mention', 'go', 'tcheky', 'karyo', 'french', 'actor', 'always', 'aura', 'menace', 'suits', 'well', 'also', 'great', 'comedy', 'br', 'br', 'nigel', 'cole', 'finds', 'perfect', 'tone', 'saving', 'grace', 'charm', 'one', 'problems', 'british', 'humor', 'energy', 'seems', 'drained', 'film', 'film', 'thoroughly', 'likable', 'always', 'amusing', 'say', 'saving', 'grace', 'likable', 'movie', 'leave', 'grin', 'good', 'feeling', 'movie', 'comedy', 'boast', 'two', 'three', 'scenes', 'nothing', 'short', 'br', 'br', 'problem', 'film', 'climax', 'little', 'confusing', 'questions', 'answered', 'though', 'ending', 'boasts', 'unexpected', 'br', 'br', 'see', 'saving', 'grace', 'especially', 'bad', 'day'], tags=['REV_25'])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2v_reviews[25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import Doc2Vec\n",
    "\n",
    "n_dim = 30\n",
    "\n",
    "d2v_model = Doc2Vec(d2v_reviews,size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.0631503 ,  0.0511961 ,  0.05992578,  0.0918224 ,  0.08400291,\n",
       "       -0.03525776,  0.04899835,  0.0027545 , -0.03045426,  0.06144393,\n",
       "       -0.08076708, -0.00165234,  0.07002113,  0.05277919,  0.03682449,\n",
       "        0.04821666,  0.00528483, -0.03040392,  0.07209196, -0.02712625,\n",
       "        0.0763872 ,  0.17796735, -0.05163846, -0.04621296, -0.06108721,\n",
       "       -0.03243967,  0.03553853,  0.11175599,  0.04035437, -0.00036282], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2v_model.docvecs['REV_3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(d2v_model.docvecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "for i in range(len(data_train)):\n",
    "    X_train.append(d2v_model.docvecs['REV_'+str(i)])\n",
    "    y_train.append(data_train['Sentiment'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "clf = SVC()\n",
    "clf = clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(analyzer=lambda x: x, min_df=10)\n",
    "matrix = vectorizer.fit_transform(reviews)\n",
    "tfidf = dict(zip(vectorizer.get_feature_names(), vectorizer.idf_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_word_vector(l,size):\n",
    "    vector = np.zeros(size).reshape((1,size))\n",
    "    count = 0.\n",
    "    for word in l:\n",
    "        try:\n",
    "            vector += d2v_model.wv[word].reshape((1, size)) * tfidf[word]\n",
    "            count+=1\n",
    "        except KeyError:\n",
    "            continue\n",
    "            \n",
    "    if count!=0:\n",
    "        vector /= count\n",
    "    return vector  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import scale\n",
    "\n",
    "data_test = pd.concat([pos_test_data,neg_test_data],ignore_index = True)\n",
    "data_test = data_test.sample(frac=0.3).reset_index(drop=True)\n",
    "\n",
    "validation_reviews = []\n",
    "\n",
    "for index,row in data_test.iterrows():\n",
    "    text = (row['Text'].lower())\n",
    "    validation_reviews.append(textclean(text))\n",
    "    \n",
    "X_val = []\n",
    "y_val = []\n",
    "\n",
    "for i in range(len(data_test)):\n",
    "    converted_review = create_word_vector(validation_reviews[i],n_dim)\n",
    "    X_val.append(converted_review)\n",
    "    y_val.append(data_test['Sentiment'][i])\n",
    "        \n",
    "X_val = np.concatenate(X_val)\n",
    "X_val = scale(X_val)\n",
    "y_val = np.array(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n"
     ]
    }
   ],
   "source": [
    "print(clf.predict(X_val[4].reshape(1,-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I didn't hate this movie as much as some on my all time black list, but I consider it a total wast of film. Jeremy Irons, Iron Jeremy, Ron Jeremy. Think about it. Scene one is very good, all the rest are crap.\""
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test['Text'][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.795733333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(accuracy_score(y_val,clf.predict(X_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
