{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "pos_train_data = pd.read_csv('train_pos.tsv',sep = '\\t')\n",
    "neg_train_data = pd.read_csv('train_neg.tsv',sep = '\\t')\n",
    "pos_test_data = pd.read_csv('test_pos.tsv',sep = '\\t')\n",
    "neg_test_data = pd.read_csv('test_neg.tsv',sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pos_train_data = pos_train_data[['Text','Sentiment']]\n",
    "neg_train_data = neg_train_data[['Text','Sentiment']]\n",
    "pos_test_data = pos_test_data[['Text','Sentiment']]\n",
    "neg_test_data = neg_test_data[['Text','Sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I can't believe this is on DVD. Even less it w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I admit I had no idea what to expect before vi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This is very much not the sort of movie for wh...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Difficult to call The Grudge a horror movie. A...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In order to rate this movie fairly you have to...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Sentiment\n",
       "0  I can't believe this is on DVD. Even less it w...          0\n",
       "1  I admit I had no idea what to expect before vi...          1\n",
       "2  This is very much not the sort of movie for wh...          1\n",
       "3  Difficult to call The Grudge a horror movie. A...          0\n",
       "4  In order to rate this movie fairly you have to...          1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train = pd.concat([pos_train_data,neg_train_data],ignore_index = True)\n",
    "data_train = data_train.sample(frac=1).reset_index(drop=True)\n",
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>If a copy of this movie fell into the wrong ha...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>My Mother Frank begins as a warm, amiable come...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>An amazing film, I've only just seen it and I ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This movie is a perfect example of Barkers cin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I do not find this show at all funny. I actual...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Sentiment\n",
       "0  If a copy of this movie fell into the wrong ha...          0\n",
       "1  My Mother Frank begins as a warm, amiable come...          1\n",
       "2  An amazing film, I've only just seen it and I ...          1\n",
       "3  This movie is a perfect example of Barkers cin...          1\n",
       "4  I do not find this show at all funny. I actual...          0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test = pd.concat([pos_test_data,neg_test_data],ignore_index = True)\n",
    "data_test = data_test.sample(frac=1).reset_index(drop=True)\n",
    "data_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "table = str.maketrans('', '', punctuation)\n",
    "\n",
    "def textclean(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [word for word in tokens if word.isalpha()]\n",
    "    tokens = [w.translate(table) for w in tokens]\n",
    "    tokens = [word for word in tokens if not word in stop_words]\n",
    "    tokens = [word for word in tokens if len(word) > 1]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ca',\n",
       " 'believe',\n",
       " 'dvd',\n",
       " 'even',\n",
       " 'less',\n",
       " 'available',\n",
       " 'local',\n",
       " 'video',\n",
       " 'br',\n",
       " 'br',\n",
       " 'argue',\n",
       " 'good',\n",
       " 'movie',\n",
       " 'take',\n",
       " 'consideration',\n",
       " 'budget',\n",
       " 'find',\n",
       " 'funny',\n",
       " 'would',\n",
       " 'find',\n",
       " 'bad',\n",
       " 'whichever',\n",
       " 'br',\n",
       " 'br',\n",
       " 'still',\n",
       " 'funny',\n",
       " 'read',\n",
       " 'following',\n",
       " 'another',\n",
       " 'review',\n",
       " 'dramatics',\n",
       " 'aside',\n",
       " 'love',\n",
       " 'horror',\n",
       " 'love',\n",
       " 'something',\n",
       " 'along',\n",
       " 'lines',\n",
       " 'duel',\n",
       " 'updated',\n",
       " 'little',\n",
       " 'story',\n",
       " 'pretty',\n",
       " 'girls',\n",
       " 'thrown',\n",
       " 'love',\n",
       " 'movie',\n",
       " 'br',\n",
       " 'br',\n",
       " 'shame',\n",
       " 'comparing',\n",
       " 'two',\n",
       " 'br',\n",
       " 'br',\n",
       " 'give',\n",
       " 'since',\n",
       " 'ca',\n",
       " 'give',\n",
       " 'see',\n",
       " 'way',\n",
       " 'movie',\n",
       " 'could',\n",
       " 'entertaining']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews = []\n",
    "\n",
    "for index,row in data_train.iterrows():\n",
    "    text = (row['Text'].lower())    \n",
    "    reviews.append(textclean(text))\n",
    "reviews[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "n_dim = 100\n",
    "\n",
    "w2v_model = Word2Vec(reviews,min_count=5,size=n_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.34266835, -0.48946238,  0.16992585, -1.59589171,  0.20816202,\n",
       "       -0.58867174,  0.42529151,  1.18220663,  1.0828265 , -0.31273049,\n",
       "       -0.44492871,  0.37714729,  0.03535983,  1.28016639, -1.69150853,\n",
       "        0.86141825,  0.74454904,  0.37987161,  1.29428494, -2.6220355 ,\n",
       "       -1.67638373, -0.55473596, -0.31270647,  0.40307197,  0.74079692,\n",
       "       -0.90968764,  0.27629927, -0.55407161, -0.76619291,  0.47750685,\n",
       "       -1.01419616,  0.67485195,  1.66792023, -0.93714583, -0.83445334,\n",
       "       -1.12781429,  0.07898249,  0.70058185, -0.47937781,  1.26753855,\n",
       "       -1.76214159, -1.39057183,  0.027617  , -0.2262345 , -0.32025877,\n",
       "        1.23497283, -0.57548404,  0.26772857,  0.01747596, -0.83560508,\n",
       "        1.2832607 ,  1.0841378 ,  0.09105023,  0.03972418,  1.04888999,\n",
       "       -0.07206379,  0.3120141 ,  1.21296299, -0.23066349, -1.21730089,\n",
       "        0.81291986, -0.49930614, -0.88758504, -0.66035891,  1.05875015,\n",
       "       -1.22189093, -0.45270762, -0.58284825, -1.01936829,  0.44454342,\n",
       "        0.55942172, -0.78759998, -0.0784628 , -1.64747417,  0.18567674,\n",
       "        1.08359909,  0.44493487, -1.27997077, -2.53967237, -0.36821187,\n",
       "        0.6124199 ,  0.51504529, -0.47393051, -0.62091213, -0.21868208,\n",
       "        0.18188362, -0.8973397 ,  0.19815522, -1.77215195,  0.48548618,\n",
       "       -0.75516438, -0.27377781, -1.22687685, -1.41529107,  0.00736537,\n",
       "        0.93945491,  0.04459641,  2.37315536, -0.51856416,  0.35843563], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv['nice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'believe'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "linked_reviews = list(itertools.chain.from_iterable(reviews))\n",
    "\n",
    "vocab_freq = dict()\n",
    "\n",
    "linked_reviews[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for word in linked_reviews:\n",
    "    if word not in vocab_freq:\n",
    "        vocab_freq[word] = 1\n",
    "    else:\n",
    "        vocab_freq[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'preserving': 7,\n",
       " 'massachusettes': 1,\n",
       " 'equal': 137,\n",
       " 'slender': 8,\n",
       " 'turveydrop': 1,\n",
       " 'rohauer': 1,\n",
       " 'alfre': 17,\n",
       " 'emptiest': 1,\n",
       " 'lumber': 4,\n",
       " 'slambang': 1,\n",
       " 'podges': 1,\n",
       " 'chalice': 8,\n",
       " 'goggles': 7,\n",
       " 'slowed': 16,\n",
       " 'bodied': 3,\n",
       " 'mythically': 2,\n",
       " 'sanitorium': 3,\n",
       " 'unsettle': 1,\n",
       " 'gram': 36,\n",
       " 'olajima': 1,\n",
       " 'vogel': 4,\n",
       " 'purchased': 90,\n",
       " 'knifing': 1,\n",
       " 'leander': 1,\n",
       " 'accomplices': 5,\n",
       " 'ungratifying': 1,\n",
       " 'networked': 1,\n",
       " 'approporiately': 1,\n",
       " 'hocking': 1,\n",
       " 'lambastes': 1,\n",
       " 'olosio': 1,\n",
       " 'aya': 8,\n",
       " 'unbearably': 29,\n",
       " 'regroup': 5,\n",
       " 'entertainers': 15,\n",
       " 'cowed': 3,\n",
       " 'unwrapped': 1,\n",
       " 'westlake': 2,\n",
       " 'uni': 8,\n",
       " 'incidentals': 1,\n",
       " 'dramaticisation': 1,\n",
       " 'reestablishing': 1,\n",
       " 'kuala': 1,\n",
       " 'granite': 2,\n",
       " 'whisperish': 1,\n",
       " 'frech': 1,\n",
       " 'garish': 21,\n",
       " 'petersson': 2,\n",
       " 'covent': 1,\n",
       " 'lakin': 1,\n",
       " 'despaired': 2,\n",
       " 'inexistent': 3,\n",
       " 'ditsy': 12,\n",
       " 'comig': 1,\n",
       " 'congratulations': 29,\n",
       " 'graphics': 164,\n",
       " 'snickered': 2,\n",
       " 'coachella': 1,\n",
       " 'objection': 12,\n",
       " 'khali': 2,\n",
       " 'insensitive': 20,\n",
       " 'lacked': 120,\n",
       " 'charlene': 3,\n",
       " 'spacey': 83,\n",
       " 'josephine': 9,\n",
       " 'quake': 3,\n",
       " 'loony': 37,\n",
       " 'oscar': 745,\n",
       " 'realism': 254,\n",
       " 'oozin': 1,\n",
       " 'elkaïm': 3,\n",
       " 'negotiations': 2,\n",
       " 'reno': 39,\n",
       " 'strip': 125,\n",
       " 'brita': 1,\n",
       " 'uta': 1,\n",
       " 'untouched': 20,\n",
       " 'waking': 46,\n",
       " 'circumstance': 29,\n",
       " 'scotian': 1,\n",
       " 'slamdunk': 1,\n",
       " 'uncharacteristically': 10,\n",
       " 'instructor': 28,\n",
       " 'digi': 5,\n",
       " 'mazurki': 2,\n",
       " 'resemblence': 4,\n",
       " 'hairpin': 1,\n",
       " 'yobs': 2,\n",
       " 'resold': 1,\n",
       " 'subscribed': 4,\n",
       " 'silverbears': 1,\n",
       " 'privation': 4,\n",
       " 'consigned': 6,\n",
       " 'swedish': 112,\n",
       " 'puritanical': 7,\n",
       " 'sarafina': 10,\n",
       " 'mcguire': 14,\n",
       " 'miles': 254,\n",
       " 'maldera': 2,\n",
       " 'slightest': 120,\n",
       " 'slowdown': 2,\n",
       " 'imbalance': 4,\n",
       " 'foregrounds': 1,\n",
       " 'careful': 87,\n",
       " 'thou': 20,\n",
       " 'thaddeus': 3,\n",
       " 'shalt': 3,\n",
       " 'crucifi': 1,\n",
       " 'yelling': 91,\n",
       " 'sydney': 56,\n",
       " 'spectable': 1,\n",
       " 'cleansed': 3,\n",
       " 'scarry': 1,\n",
       " 'wachtang': 1,\n",
       " 'zakariadze': 1,\n",
       " 'mosaic': 4,\n",
       " 'shamelessly': 35,\n",
       " 'jest': 5,\n",
       " 'transfers': 11,\n",
       " 'inherently': 29,\n",
       " 'sokurov': 4,\n",
       " 'kaushik': 2,\n",
       " 'abut': 4,\n",
       " 'boogaloo': 2,\n",
       " 'thoes': 2,\n",
       " 'recognise': 30,\n",
       " 'poignancy': 29,\n",
       " 'gorefests': 2,\n",
       " 'replicate': 13,\n",
       " 'taandav': 1,\n",
       " 'sceam': 1,\n",
       " 'avatars': 1,\n",
       " 'jolene': 4,\n",
       " 'intrudes': 3,\n",
       " 'copiers': 1,\n",
       " 'asst': 2,\n",
       " 'mistaken': 104,\n",
       " 'roan': 1,\n",
       " 'caleb': 18,\n",
       " 'astronaut': 35,\n",
       " 'seppuka': 1,\n",
       " 'join': 167,\n",
       " 'sayonara': 14,\n",
       " 'incomprehensible': 85,\n",
       " 'pfennig': 1,\n",
       " 'perilous': 16,\n",
       " 'slimmed': 1,\n",
       " 'respect': 472,\n",
       " 'zé': 1,\n",
       " 'phenolic': 1,\n",
       " 'vangelis': 1,\n",
       " 'pernell': 8,\n",
       " 'ehrlich': 2,\n",
       " 'ri': 1,\n",
       " 'rolled': 80,\n",
       " 'flashlight': 16,\n",
       " 'timbrook': 1,\n",
       " 'jong': 2,\n",
       " 'showstopping': 1,\n",
       " 'grandfathers': 3,\n",
       " 'physicallity': 1,\n",
       " 'hanks': 138,\n",
       " 'anilji': 2,\n",
       " 'third': 701,\n",
       " 'unferth': 3,\n",
       " 'bachstage': 1,\n",
       " 'omnipresence': 1,\n",
       " 'tarlow': 1,\n",
       " 'depth': 475,\n",
       " 'genesis': 17,\n",
       " 'tiffany': 16,\n",
       " 'opposite': 263,\n",
       " 'bassett': 12,\n",
       " 'timeing': 1,\n",
       " 'coincide': 9,\n",
       " 'leased': 2,\n",
       " 'harking': 2,\n",
       " 'mopping': 1,\n",
       " 'inaccuracy': 11,\n",
       " 'gimmicks': 34,\n",
       " 'mehki': 2,\n",
       " 'duc': 11,\n",
       " 'opera': 353,\n",
       " 'parfrey': 1,\n",
       " 'exciting': 501,\n",
       " 'peculiarly': 5,\n",
       " 'moragn': 1,\n",
       " 'darth': 50,\n",
       " 'fundamentally': 19,\n",
       " 'talky': 46,\n",
       " 'mehra': 3,\n",
       " 'correctly': 77,\n",
       " 'arcam': 1,\n",
       " 'philly': 9,\n",
       " 'doublebill': 1,\n",
       " 'imported': 7,\n",
       " 'logan': 79,\n",
       " 'tones': 45,\n",
       " 'angelou': 1,\n",
       " 'thames': 8,\n",
       " 'jabberwocky': 1,\n",
       " 'submit': 34,\n",
       " 'urdhu': 1,\n",
       " 'bulked': 2,\n",
       " 'academic': 35,\n",
       " 'machi': 6,\n",
       " 'batis': 1,\n",
       " 'implores': 3,\n",
       " 'dirtiness': 1,\n",
       " 'overthrown': 4,\n",
       " 'mental': 304,\n",
       " 'tmtm': 10,\n",
       " 'rigs': 5,\n",
       " 'leicester': 3,\n",
       " 'subjugated': 5,\n",
       " 'saboteur': 5,\n",
       " 'nantes': 1,\n",
       " 'incandescent': 2,\n",
       " 'risibly': 1,\n",
       " 'marking': 22,\n",
       " 'nee': 1,\n",
       " 'docile': 11,\n",
       " 'rwanda': 3,\n",
       " 'reprisals': 1,\n",
       " 'lungren': 6,\n",
       " 'blimp': 6,\n",
       " 'barcode': 2,\n",
       " 'eon': 8,\n",
       " 'ari': 6,\n",
       " 'ewing': 5,\n",
       " 'conversion': 18,\n",
       " 'pussycat': 3,\n",
       " 'raiment': 1,\n",
       " 'alienate': 34,\n",
       " 'expeditioners': 1,\n",
       " 'thanx': 2,\n",
       " 'boogeman': 1,\n",
       " 'programs': 66,\n",
       " 'cpt': 5,\n",
       " 'missionary': 20,\n",
       " 'arrange': 22,\n",
       " 'flicka': 2,\n",
       " 'outright': 64,\n",
       " 'mmb': 1,\n",
       " 'jeopardizes': 1,\n",
       " 'square': 83,\n",
       " 'aikens': 2,\n",
       " 'sermonizing': 3,\n",
       " 'hrithik': 1,\n",
       " 'unknowingly': 18,\n",
       " 'clicheish': 2,\n",
       " 'forge': 8,\n",
       " 'essayist': 1,\n",
       " 'beneath': 102,\n",
       " 'vander': 1,\n",
       " 'disenchanted': 6,\n",
       " 'barre': 1,\n",
       " 'portrayal': 501,\n",
       " 'mohandas': 5,\n",
       " 'emotionally': 235,\n",
       " 'obers': 1,\n",
       " 'clunkers': 6,\n",
       " 'anachronistic': 14,\n",
       " 'retracted': 1,\n",
       " 'guard': 157,\n",
       " 'chum': 7,\n",
       " 'tujunga': 1,\n",
       " 'prolix': 1,\n",
       " 'callipygian': 1,\n",
       " 'kurasowals': 1,\n",
       " 'cheyenne': 14,\n",
       " 'hurricanes': 3,\n",
       " 'spam': 5,\n",
       " 'hrpuff': 2,\n",
       " 'dello': 5,\n",
       " 'acin': 1,\n",
       " 'festivities': 9,\n",
       " 'june': 88,\n",
       " 'rating': 878,\n",
       " 'conceptions': 5,\n",
       " 'missus': 4,\n",
       " 'todo': 1,\n",
       " 'discounting': 3,\n",
       " 'aintry': 1,\n",
       " 'heldar': 3,\n",
       " 'bafta': 23,\n",
       " 'pommel': 3,\n",
       " 'frazer': 3,\n",
       " 'cs': 5,\n",
       " 'remade': 70,\n",
       " 'hauk': 1,\n",
       " 'danaza': 1,\n",
       " 'pyewacket': 7,\n",
       " 'mariel': 8,\n",
       " 'method': 97,\n",
       " 'playwrite': 1,\n",
       " 'akins': 4,\n",
       " 'hopeful': 35,\n",
       " 'wheeling': 6,\n",
       " 'glosses': 5,\n",
       " 'piloted': 5,\n",
       " 'grabovsky': 2,\n",
       " 'mishmashed': 2,\n",
       " 'serena': 4,\n",
       " 'yash': 12,\n",
       " 'jb': 2,\n",
       " 'yakking': 1,\n",
       " 'newspapers': 25,\n",
       " 'mariiines': 1,\n",
       " 'teamed': 30,\n",
       " 'slightly': 536,\n",
       " 'razed': 1,\n",
       " 'unwise': 8,\n",
       " 'supermodels': 6,\n",
       " 'tenko': 3,\n",
       " 'scotched': 1,\n",
       " 'harbours': 1,\n",
       " 'sinbad': 2,\n",
       " 'marblehead': 3,\n",
       " 'hentai': 1,\n",
       " 'suzu': 1,\n",
       " 'freshner': 1,\n",
       " 'merges': 4,\n",
       " 'riverbank': 1,\n",
       " 'help': 1865,\n",
       " 'insult': 209,\n",
       " 'spokane': 1,\n",
       " 'soavi': 2,\n",
       " 'mame': 4,\n",
       " 'hostel': 45,\n",
       " 'guildernstern': 1,\n",
       " 'handwritten': 1,\n",
       " 'iliada': 1,\n",
       " 'schieder': 4,\n",
       " 'ritt': 2,\n",
       " 'provoking': 90,\n",
       " 'havent': 9,\n",
       " 'grayscale': 1,\n",
       " 'sparks': 48,\n",
       " 'laxitive': 1,\n",
       " 'forgotten': 333,\n",
       " 'ludicrousness': 4,\n",
       " 'kowalkski': 2,\n",
       " 'bloodrayne': 11,\n",
       " 'suraj': 4,\n",
       " 'kamp': 1,\n",
       " 'gore': 954,\n",
       " 'inquisitor': 2,\n",
       " 'dino': 23,\n",
       " 'akosua': 3,\n",
       " 'humans': 307,\n",
       " 'soundstage': 12,\n",
       " 'playschool': 2,\n",
       " 'dominos': 1,\n",
       " 'charmian': 2,\n",
       " 'kebab': 1,\n",
       " 'hammerhead': 32,\n",
       " 'vats': 1,\n",
       " 'crassly': 4,\n",
       " 'alarmists': 1,\n",
       " 'posterior': 5,\n",
       " 'holender': 1,\n",
       " 'color': 390,\n",
       " 'overplays': 6,\n",
       " 'bilko': 17,\n",
       " 'rubbishes': 1,\n",
       " 'immorality': 12,\n",
       " 'henze': 1,\n",
       " 'buttgereit': 25,\n",
       " 'talkd': 1,\n",
       " 'hamish': 4,\n",
       " 'vijay': 18,\n",
       " 'allayli': 1,\n",
       " 'nl': 1,\n",
       " 'sheena': 3,\n",
       " 'bizet': 7,\n",
       " 'colorist': 1,\n",
       " 'laterally': 1,\n",
       " 'romerfeller': 1,\n",
       " 'bice': 1,\n",
       " 'consists': 144,\n",
       " 'poop': 19,\n",
       " 'tendresse': 1,\n",
       " 'ermey': 2,\n",
       " 'pattes': 1,\n",
       " 'gaimans': 1,\n",
       " 'rpm': 5,\n",
       " 'optimum': 2,\n",
       " 'rolling': 171,\n",
       " 'incantations': 1,\n",
       " 'nyfiken': 2,\n",
       " 'oni': 1,\n",
       " 'embeds': 1,\n",
       " 'drivin': 1,\n",
       " 'manilow': 1,\n",
       " 'rossini': 2,\n",
       " 'hornby': 8,\n",
       " 'paper': 193,\n",
       " 'boards': 39,\n",
       " 'earthbound': 3,\n",
       " 'decay': 22,\n",
       " 'thundercleese': 1,\n",
       " 'eruptions': 3,\n",
       " 'despertar': 1,\n",
       " 'rabidly': 2,\n",
       " 'aprox': 1,\n",
       " 'testimonials': 3,\n",
       " 'auld': 2,\n",
       " 'rotj': 16,\n",
       " 'poms': 4,\n",
       " 'gatesville': 1,\n",
       " 'compare': 322,\n",
       " 'beatin': 1,\n",
       " 'mercs': 1,\n",
       " 'hollywoon': 1,\n",
       " 'sawed': 4,\n",
       " 'ca': 3543,\n",
       " 'salt': 64,\n",
       " 'krimis': 2,\n",
       " 'lachman': 2,\n",
       " 'sledding': 3,\n",
       " 'game': 1214,\n",
       " 'lolol': 1,\n",
       " 'mclaren': 3,\n",
       " 'assuming': 68,\n",
       " 'overlookable': 1,\n",
       " 'curiously': 49,\n",
       " 'reflected': 48,\n",
       " 'vereen': 5,\n",
       " 'albaladejo': 1,\n",
       " 'deesh': 1,\n",
       " 'arjuna': 1,\n",
       " 'roundabout': 6,\n",
       " 'mantra': 10,\n",
       " 'espionage': 41,\n",
       " 'toone': 1,\n",
       " 'accomplice': 22,\n",
       " 'nineveh': 1,\n",
       " 'deathy': 1,\n",
       " 'unchained': 2,\n",
       " 'crescendoing': 1,\n",
       " 'pocus': 4,\n",
       " 'superhero': 111,\n",
       " 'broadcasters': 1,\n",
       " 'ordering': 20,\n",
       " 'cuckold': 5,\n",
       " 'youngers': 1,\n",
       " 'upstate': 11,\n",
       " 'sluty': 1,\n",
       " 'mane': 2,\n",
       " 'wolfen': 3,\n",
       " 'elevating': 6,\n",
       " 'gaga': 2,\n",
       " 'poker': 60,\n",
       " 'ovies': 1,\n",
       " 'regarded': 72,\n",
       " 'wintry': 6,\n",
       " 'paleontologist': 1,\n",
       " 'siam': 8,\n",
       " 'prolly': 5,\n",
       " 'webb': 15,\n",
       " 'squashing': 1,\n",
       " 'episdoe': 1,\n",
       " 'brogado': 1,\n",
       " 'victims': 354,\n",
       " 'doctrinal': 2,\n",
       " 'hight': 3,\n",
       " 'ernie': 46,\n",
       " 'clatter': 1,\n",
       " 'cornucopia': 3,\n",
       " 'izzy': 2,\n",
       " 'otaku': 7,\n",
       " 'flagstaff': 2,\n",
       " 'bowel': 7,\n",
       " 'stakes': 27,\n",
       " 'primitiveness': 1,\n",
       " 'hacker': 14,\n",
       " 'lubricated': 1,\n",
       " 'bombsight': 1,\n",
       " 'akira': 25,\n",
       " 'deuce': 6,\n",
       " 'crapsterpiece': 1,\n",
       " 'sandy': 40,\n",
       " 'commiseration': 1,\n",
       " 'destination': 45,\n",
       " 'louco': 1,\n",
       " 'bejard': 1,\n",
       " 'counters': 6,\n",
       " 'benefactor': 7,\n",
       " 'investigated': 15,\n",
       " 'handkerchiefs': 1,\n",
       " 'fuel': 46,\n",
       " 'costener': 1,\n",
       " 'stefaniuk': 2,\n",
       " 'eschatology': 2,\n",
       " 'tereasa': 1,\n",
       " 'professionals': 46,\n",
       " 'cortese': 2,\n",
       " 'daoist': 2,\n",
       " 'ordet': 1,\n",
       " 'yeoman': 6,\n",
       " 'maddie': 4,\n",
       " 'davi': 1,\n",
       " 'ahahahah': 1,\n",
       " 'mes': 9,\n",
       " 'donal': 2,\n",
       " 'psyches': 2,\n",
       " 'blemish': 3,\n",
       " 'underaged': 1,\n",
       " 'scorpiolina': 1,\n",
       " 'luxuriant': 3,\n",
       " 'isoyg': 3,\n",
       " 'gerald': 28,\n",
       " 'priestley': 8,\n",
       " 'jacy': 1,\n",
       " 'anymore': 314,\n",
       " 'dermatonecrotic': 1,\n",
       " 'tholomyes': 1,\n",
       " 'gonzalez': 12,\n",
       " 'militarize': 1,\n",
       " 'retrace': 1,\n",
       " 'postino': 2,\n",
       " 'christmases': 5,\n",
       " 'resmblance': 1,\n",
       " 'passing': 186,\n",
       " 'cares': 221,\n",
       " 'roby': 1,\n",
       " 'bangville': 1,\n",
       " 'counterweight': 2,\n",
       " 'fav': 11,\n",
       " 'adviser': 18,\n",
       " 'elizondo': 11,\n",
       " 'abetted': 15,\n",
       " 'dismissive': 4,\n",
       " 'rumors': 31,\n",
       " 'turpentine': 1,\n",
       " 'pube': 1,\n",
       " 'damiana': 1,\n",
       " 'urine': 4,\n",
       " 'crew': 556,\n",
       " 'bunch': 805,\n",
       " 'wantabee': 1,\n",
       " 'arnis': 1,\n",
       " 'mcclain': 1,\n",
       " 'unearth': 2,\n",
       " 'fullscreen': 3,\n",
       " 'summoned': 14,\n",
       " 'doings': 7,\n",
       " 'persistently': 4,\n",
       " 'excellente': 1,\n",
       " 'krupa': 6,\n",
       " 'integral': 30,\n",
       " 'modifies': 3,\n",
       " 'marshland': 1,\n",
       " 'reichter': 1,\n",
       " 'rattler': 1,\n",
       " 'trashiness': 1,\n",
       " 'marlboro': 1,\n",
       " 'repentance': 6,\n",
       " 'rein': 4,\n",
       " 'voltron': 3,\n",
       " 'ravensteins': 1,\n",
       " 'sheez': 1,\n",
       " 'coincides': 6,\n",
       " 'shaken': 24,\n",
       " 'dibiase': 24,\n",
       " 'recollected': 1,\n",
       " 'nausium': 1,\n",
       " 'muppet': 69,\n",
       " 'guntenberg': 1,\n",
       " 'pastures': 8,\n",
       " 'consigliare': 1,\n",
       " 'doodle': 18,\n",
       " 'slagged': 1,\n",
       " 'pneumonia': 2,\n",
       " 'criminologist': 1,\n",
       " 'restaurant': 112,\n",
       " 'porters': 2,\n",
       " 'wile': 3,\n",
       " 'superbrains': 1,\n",
       " 'dirs': 1,\n",
       " 'backlots': 1,\n",
       " 'subdued': 37,\n",
       " 'flicker': 14,\n",
       " 'epiphanous': 1,\n",
       " 'entombment': 1,\n",
       " 'zombielike': 1,\n",
       " 'selectivity': 1,\n",
       " 'eneide': 1,\n",
       " 'anemic': 9,\n",
       " 'rendering': 44,\n",
       " 'minstrel': 12,\n",
       " 'cozies': 1,\n",
       " 'abdullah': 1,\n",
       " 'garron': 2,\n",
       " 'dynamo': 6,\n",
       " 'pent': 2,\n",
       " 'withered': 2,\n",
       " 'disharmoniously': 1,\n",
       " 'berwick': 1,\n",
       " 'tempra': 1,\n",
       " 'declarations': 2,\n",
       " 'squidoids': 1,\n",
       " 'irreparably': 5,\n",
       " 'blush': 11,\n",
       " 'relationsip': 1,\n",
       " 'binoche': 31,\n",
       " 'timmons': 2,\n",
       " 'combination': 230,\n",
       " 'catacombs': 3,\n",
       " 'encircle': 1,\n",
       " 'newsreels': 5,\n",
       " 'yamamoto': 8,\n",
       " 'uncoventional': 1,\n",
       " 'invigored': 1,\n",
       " 'cornea': 2,\n",
       " 'whizzing': 2,\n",
       " 'vincenzo': 42,\n",
       " 'av': 3,\n",
       " 'dsv': 1,\n",
       " 'doctrine': 10,\n",
       " 'downpour': 3,\n",
       " 'circus': 70,\n",
       " 'greek': 110,\n",
       " 'mexicanos': 1,\n",
       " 'drycoff': 1,\n",
       " 'soars': 6,\n",
       " 'gruff': 39,\n",
       " 'izoo': 1,\n",
       " 'sickos': 2,\n",
       " 'bungy': 1,\n",
       " 'mistress': 82,\n",
       " 'dreyfuss': 44,\n",
       " 'alock': 1,\n",
       " 'partido': 1,\n",
       " 'workmanlike': 11,\n",
       " 'bourvier': 1,\n",
       " 'arrogant': 99,\n",
       " 'lachrymose': 4,\n",
       " 'sir': 181,\n",
       " 'oxide': 3,\n",
       " 'kebbel': 1,\n",
       " 'stylistics': 4,\n",
       " 'rabified': 1,\n",
       " 'rods': 3,\n",
       " 'certificates': 2,\n",
       " 'typos': 1,\n",
       " 'spermikins': 1,\n",
       " 'pressburger': 16,\n",
       " 'cacoyannis': 11,\n",
       " 'visitors': 29,\n",
       " 'welds': 1,\n",
       " 'sarge': 5,\n",
       " 'boobs': 41,\n",
       " 'jigsaw': 40,\n",
       " 'charecters': 3,\n",
       " 'rednecks': 16,\n",
       " 'documentarians': 2,\n",
       " 'sorrier': 1,\n",
       " 'quanxin': 1,\n",
       " 'contract': 126,\n",
       " 'dwars': 1,\n",
       " 'mente': 1,\n",
       " 'gambler': 25,\n",
       " 'libbed': 3,\n",
       " 'rogers': 161,\n",
       " 'founding': 11,\n",
       " 'frankbob': 1,\n",
       " 'endeth': 3,\n",
       " 'feyder': 9,\n",
       " 'aye': 4,\n",
       " 'bigley': 2,\n",
       " 'elizbeth': 1,\n",
       " 'skyways': 1,\n",
       " 'sixes': 1,\n",
       " 'harvey': 105,\n",
       " 'givens': 3,\n",
       " 'soot': 1,\n",
       " 'karmically': 1,\n",
       " 'pond': 34,\n",
       " 'kazumi': 4,\n",
       " 'persuasive': 14,\n",
       " 'flannel': 3,\n",
       " 'cypher': 58,\n",
       " 'baldwin': 78,\n",
       " 'cohn': 20,\n",
       " 'expiating': 1,\n",
       " 'embarassed': 2,\n",
       " 'wunderkinds': 1,\n",
       " 'farrah': 40,\n",
       " 'irregular': 4,\n",
       " 'louey': 1,\n",
       " 'andie': 27,\n",
       " 'cyndy': 2,\n",
       " 'misgauged': 1,\n",
       " 'comprise': 10,\n",
       " 'bitterman': 2,\n",
       " 'expressly': 2,\n",
       " 'prohibitive': 1,\n",
       " 'consummates': 1,\n",
       " 'blik': 2,\n",
       " 'hastening': 1,\n",
       " 'fated': 7,\n",
       " 'cute': 560,\n",
       " 'winterbottom': 2,\n",
       " 'nuttier': 3,\n",
       " 'agitprop': 4,\n",
       " 'irons': 24,\n",
       " 'hoyts': 3,\n",
       " 'nips': 2,\n",
       " 'heared': 1,\n",
       " 'obtain': 64,\n",
       " 'roeg': 30,\n",
       " 'uncontrollably': 9,\n",
       " 'lampidorra': 3,\n",
       " 'visage': 10,\n",
       " 'frustrating': 77,\n",
       " 'symphony': 13,\n",
       " 'pique': 4,\n",
       " 'popinjays': 1,\n",
       " 'retarted': 1,\n",
       " 'solidly': 23,\n",
       " 'winamp': 1,\n",
       " 'zipping': 3,\n",
       " 'shirley': 103,\n",
       " 'iambic': 2,\n",
       " 'hadddd': 1,\n",
       " 'groovy': 25,\n",
       " 'glossty': 1,\n",
       " 'dodekakuple': 1,\n",
       " 'befouled': 1,\n",
       " 'guliano': 1,\n",
       " 'fluctuation': 1,\n",
       " 'explorers': 11,\n",
       " 'greenlit': 4,\n",
       " 'snoozing': 6,\n",
       " 'empathy': 79,\n",
       " 'dreamily': 3,\n",
       " 'chavez': 70,\n",
       " 'scanty': 2,\n",
       " 'pl': 2,\n",
       " 'heinkel': 1,\n",
       " 'fois': 5,\n",
       " 'underuse': 1,\n",
       " 'suzie': 4,\n",
       " 'nether': 1,\n",
       " 'dingos': 5,\n",
       " 'overstimulate': 1,\n",
       " 'sasquatsh': 1,\n",
       " 'manipulated': 40,\n",
       " 'compatable': 1,\n",
       " 'jone': 2,\n",
       " 'depends': 67,\n",
       " 'brutal': 297,\n",
       " 'itd': 1,\n",
       " 'elated': 3,\n",
       " 'abanks': 1,\n",
       " 'sistahs': 1,\n",
       " 'communal': 3,\n",
       " 'telemarketers': 1,\n",
       " 'palma': 106,\n",
       " 'capones': 1,\n",
       " 'predefined': 1,\n",
       " 'worthy': 310,\n",
       " 'illogic': 2,\n",
       " 'perform': 147,\n",
       " 'homing': 1,\n",
       " 'marilu': 9,\n",
       " 'looong': 1,\n",
       " 'extravagant': 25,\n",
       " 'wildcard': 1,\n",
       " 'yossarian': 1,\n",
       " 'helter': 1,\n",
       " 'paralysed': 1,\n",
       " 'gladiator': 37,\n",
       " 'kinng': 1,\n",
       " 'backbiting': 3,\n",
       " 'divide': 16,\n",
       " 'kicked': 97,\n",
       " 'deerfield': 4,\n",
       " 'knives': 36,\n",
       " 'page': 360,\n",
       " 'bredeston': 2,\n",
       " 'biehn': 16,\n",
       " 'evacuees': 2,\n",
       " 'gupta': 1,\n",
       " 'saxaphone': 1,\n",
       " 'babtise': 1,\n",
       " 'hurtle': 1,\n",
       " 'eugenio': 1,\n",
       " 'porto': 2,\n",
       " 'suba': 4,\n",
       " 'slug': 31,\n",
       " 'ziggy': 4,\n",
       " 'cranberry': 1,\n",
       " 'mapping': 1,\n",
       " 'lavigne': 3,\n",
       " 'translates': 17,\n",
       " 'friday': 189,\n",
       " 'chruch': 1,\n",
       " 'fricker': 28,\n",
       " 'delight': 152,\n",
       " 'keusch': 6,\n",
       " 'parisian': 26,\n",
       " 'silvers': 16,\n",
       " 'ledoyen': 2,\n",
       " 'gypsy': 41,\n",
       " 'lush': 73,\n",
       " 'transferred': 31,\n",
       " 'jettisons': 3,\n",
       " 'comprehended': 2,\n",
       " 'food': 310,\n",
       " 'nubo': 1,\n",
       " 'glamorized': 8,\n",
       " 'gouald': 5,\n",
       " 'birkina': 1,\n",
       " 'westernisation': 1,\n",
       " 'somethings': 27,\n",
       " 'geometrical': 6,\n",
       " 'younes': 1,\n",
       " 'autopsy': 16,\n",
       " 'trimester': 1,\n",
       " 'yonica': 10,\n",
       " 'krauss': 2,\n",
       " 'squishy': 1,\n",
       " 'dainiken': 1,\n",
       " 'coronel': 4,\n",
       " 'cordaraby': 1,\n",
       " 'chokes': 7,\n",
       " 'licencing': 1,\n",
       " 'parke': 1,\n",
       " 'hashing': 1,\n",
       " 'ferilli': 1,\n",
       " 'rydstrom': 1,\n",
       " 'chauffeur': 18,\n",
       " 'frequent': 85,\n",
       " 'vocal': 64,\n",
       " 'gaydar': 1,\n",
       " 'alleged': 55,\n",
       " 'geological': 3,\n",
       " 'tiptoe': 1,\n",
       " 'foreknowledge': 1,\n",
       " 'stumble': 45,\n",
       " 'rochfort': 1,\n",
       " 'verity': 2,\n",
       " 'burtonesque': 2,\n",
       " 'repetitiveness': 1,\n",
       " 'resembled': 27,\n",
       " 'cyclonic': 3,\n",
       " 'wadsworth': 1,\n",
       " 'precursors': 2,\n",
       " 'homunculi': 1,\n",
       " 'koppikar': 3,\n",
       " 'precedes': 12,\n",
       " 'cellar': 20,\n",
       " 'shrill': 37,\n",
       " 'chariots': 3,\n",
       " 'bandaur': 1,\n",
       " 'dang': 10,\n",
       " 'manhole': 4,\n",
       " 'authority': 98,\n",
       " 'nobly': 5,\n",
       " 'suspiciouly': 1,\n",
       " 'passworthys': 1,\n",
       " 'unsub': 1,\n",
       " 'calcium': 2,\n",
       " 'hawn': 49,\n",
       " 'busta': 11,\n",
       " 'nop': 1,\n",
       " 'grieving': 30,\n",
       " 'erratically': 3,\n",
       " 'darcy': 11,\n",
       " 'deix': 1,\n",
       " 'hannan': 1,\n",
       " 'affectionately': 11,\n",
       " 'emphatic': 6,\n",
       " 'ewoks': 38,\n",
       " 'kolos': 2,\n",
       " 'louque': 21,\n",
       " 'attacks': 151,\n",
       " 'gnarly': 6,\n",
       " 'pendanski': 2,\n",
       " 'cgi': 310,\n",
       " 'farr': 3,\n",
       " 'suppressor': 2,\n",
       " 'cullen': 5,\n",
       " 'hewlitt': 1,\n",
       " 'classed': 11,\n",
       " 'dalmations': 11,\n",
       " 'clump': 1,\n",
       " 'molla': 5,\n",
       " 'caged': 23,\n",
       " 'beatnik': 3,\n",
       " 'barricaded': 1,\n",
       " 'schrieber': 6,\n",
       " 'bedsheets': 2,\n",
       " 'yes': 1505,\n",
       " 'sidewalk': 57,\n",
       " 'sonar': 1,\n",
       " 'scences': 1,\n",
       " 'sverak': 1,\n",
       " 'berhard': 1,\n",
       " 'rad': 10,\n",
       " 'vittorio': 10,\n",
       " 'crochety': 1,\n",
       " 'pretagonist': 1,\n",
       " 'drekish': 1,\n",
       " 'stoke': 1,\n",
       " 'pokeball': 2,\n",
       " 'vandals': 3,\n",
       " 'prosthetics': 10,\n",
       " 'beats': 110,\n",
       " 'lil': 43,\n",
       " 'pricing': 2,\n",
       " 'prejudices': 35,\n",
       " 'muscleman': 1,\n",
       " 'ocurred': 1,\n",
       " 'wast': 3,\n",
       " 'siphon': 1,\n",
       " 'vapidness': 1,\n",
       " 'smirky': 3,\n",
       " 'armament': 2,\n",
       " 'hypermacho': 1,\n",
       " 'sun': 168,\n",
       " 'facials': 1,\n",
       " 'vanning': 1,\n",
       " 'inuindo': 1,\n",
       " 'katharine': 12,\n",
       " 'lighthouse': 4,\n",
       " 'auroras': 1,\n",
       " 'asiaphile': 1,\n",
       " 'pooja': 8,\n",
       " 'beauticin': 1,\n",
       " 'gutman': 1,\n",
       " 'wurman': 2,\n",
       " 'srebrenica': 4,\n",
       " 'leprosy': 4,\n",
       " 'plaudits': 6,\n",
       " 'parkes': 2,\n",
       " 'cradles': 3,\n",
       " 'mandark': 2,\n",
       " 'mongolians': 1,\n",
       " 'castigated': 1,\n",
       " 'bells': 24,\n",
       " 'mob': 151,\n",
       " 'cataclysmic': 5,\n",
       " 'goodie': 7,\n",
       " 'swath': 4,\n",
       " 'clambers': 1,\n",
       " 'headtripping': 1,\n",
       " 'steal': 245,\n",
       " 'difford': 2,\n",
       " 'stalemate': 3,\n",
       " 'beatiful': 2,\n",
       " 'obstinate': 4,\n",
       " 'kurasowa': 5,\n",
       " 'chaos': 104,\n",
       " 'bustiness': 1,\n",
       " 'amato': 4,\n",
       " 'chasers': 1,\n",
       " 'youtube': 55,\n",
       " 'miscalculated': 2,\n",
       " 'idol': 50,\n",
       " 'yards': 21,\n",
       " 'speaker': 28,\n",
       " 'succumbing': 5,\n",
       " 'mujar': 1,\n",
       " 'ugc': 1,\n",
       " 'flåklypa': 1,\n",
       " 'sulibans': 1,\n",
       " 'indian': 391,\n",
       " 'perceptions': 12,\n",
       " 'aylmer': 3,\n",
       " 'tinge': 4,\n",
       " 'sledge': 15,\n",
       " 'incestual': 1,\n",
       " 'guinea': 53,\n",
       " 'illustrating': 12,\n",
       " 'talosians': 5,\n",
       " 'edgiest': 1,\n",
       " 'rakishly': 1,\n",
       " 'likes': 464,\n",
       " 'mian': 3,\n",
       " 'outburst': 13,\n",
       " 'angelos': 1,\n",
       " 'approved': 23,\n",
       " 'xs': 1,\n",
       " 'contre': 1,\n",
       " 'pilotable': 1,\n",
       " 'yami': 2,\n",
       " 'muetos': 1,\n",
       " 'unconventionality': 2,\n",
       " 'luxury': 37,\n",
       " 'loooooooooooong': 1,\n",
       " 'sansabelt': 1,\n",
       " 'transcendence': 4,\n",
       " 'gotham': 16,\n",
       " 'exaggerated': 113,\n",
       " 'rodrix': 1,\n",
       " 'comas': 1,\n",
       " ...}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import operator\n",
    "\n",
    "sorted_vocab_freq = list(reversed(sorted(vocab_freq.items(), key=operator.itemgetter(1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71238"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sorted_vocab_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24970</th>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24971</th>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24972</th>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24973</th>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24974</th>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24975</th>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24976</th>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24977</th>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24978</th>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24979</th>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24980</th>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24981</th>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24982</th>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24983</th>\n",
       "      <td>302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24984</th>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24985</th>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24986</th>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24987</th>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24988</th>\n",
       "      <td>344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24989</th>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24990</th>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24991</th>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24992</th>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24993</th>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24994</th>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Len\n",
       "0       63\n",
       "1      101\n",
       "2      293\n",
       "3       59\n",
       "4       73\n",
       "5       71\n",
       "6       63\n",
       "7       53\n",
       "8       61\n",
       "9      109\n",
       "10      54\n",
       "11     110\n",
       "12      74\n",
       "13     213\n",
       "14     102\n",
       "15      55\n",
       "16      85\n",
       "17      37\n",
       "18      63\n",
       "19     224\n",
       "20     124\n",
       "21     305\n",
       "22      75\n",
       "23      72\n",
       "24      72\n",
       "25      72\n",
       "26      59\n",
       "27     535\n",
       "28     134\n",
       "29      37\n",
       "...    ...\n",
       "24970   63\n",
       "24971  158\n",
       "24972  124\n",
       "24973   66\n",
       "24974   82\n",
       "24975   81\n",
       "24976  147\n",
       "24977  155\n",
       "24978   51\n",
       "24979   27\n",
       "24980  195\n",
       "24981   62\n",
       "24982   56\n",
       "24983  302\n",
       "24984   19\n",
       "24985   26\n",
       "24986   63\n",
       "24987   68\n",
       "24988  344\n",
       "24989   73\n",
       "24990   90\n",
       "24991   66\n",
       "24992   66\n",
       "24993   91\n",
       "24994   82\n",
       "24995  189\n",
       "24996  272\n",
       "24997   60\n",
       "24998   74\n",
       "24999  171\n",
       "\n",
       "[25000 rows x 1 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_lengths = pd.DataFrame([len(review) for review in reviews])\n",
    "review_lengths.columns = ['Len']\n",
    "\n",
    "review_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>25000.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>118.36848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>89.42677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>63.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>88.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>144.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1409.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Len\n",
       "count  25000.00000\n",
       "mean     118.36848\n",
       "std       89.42677\n",
       "min        4.00000\n",
       "25%       63.00000\n",
       "50%       88.00000\n",
       "75%      144.00000\n",
       "max     1409.00000"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_lengths.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(265.5, -58.5)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Removal of outliers using Tukey's Method\n",
    "first_q = review_lengths.Len.quantile([0.25])[0.25]\n",
    "third_q = review_lengths.Len.quantile([0.75])[0.75]\n",
    "\n",
    "upper_threshold = third_q + 1.5*(third_q-first_q)\n",
    "lower_threshold = first_q - 1.5*(third_q-first_q)\n",
    "\n",
    "upper_threshold,lower_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(analyzer=lambda x: x, min_df=10)\n",
    "matrix = vectorizer.fit_transform(reviews)\n",
    "tfidf = dict(zip(vectorizer.get_feature_names(), vectorizer.idf_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.7163240052293349"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf['try']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_word_vector(l,size):\n",
    "    vector = np.zeros(size).reshape((1,size))\n",
    "    count = 0.\n",
    "    for word in l:\n",
    "        try:\n",
    "            vector += w2v_model[word].reshape((1, size)) * tfidf[word]\n",
    "            count+=1\n",
    "        except KeyError:\n",
    "            continue\n",
    "            \n",
    "    if count!=0:\n",
    "        vector /= count\n",
    "    return vector        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pratik/.local/lib/python3.5/site-packages/ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "for i in range(len(data_train)):\n",
    "    converted_review = create_word_vector(reviews[i],n_dim)\n",
    "    X_train.append(converted_review)\n",
    "    y_train.append(data_train['Sentiment'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import scale\n",
    "\n",
    "X_train = np.concatenate(X_train)\n",
    "X_train = scale(X_train)\n",
    "y_train = np.array(y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 100)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pratik/.local/lib/python3.5/site-packages/ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "data_test = pd.concat([pos_test_data,neg_test_data],ignore_index = True)\n",
    "data_test = data_test.sample(frac=0.3).reset_index(drop=True)\n",
    "\n",
    "validation_reviews = []\n",
    "\n",
    "for index,row in data_test.iterrows():\n",
    "    text = (row['Text'].lower())\n",
    "    validation_reviews.append(textclean(text))\n",
    "    \n",
    "X_val = []\n",
    "y_val = []\n",
    "\n",
    "for i in range(len(data_test)):\n",
    "    converted_review = create_word_vector(validation_reviews[i],n_dim)\n",
    "    X_val.append(converted_review)\n",
    "    y_val.append(data_test['Sentiment'][i])\n",
    "        \n",
    "X_val = np.concatenate(X_val)\n",
    "X_val = scale(X_val)\n",
    "y_val = np.array(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout,Activation\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(64,activation = 'relu',input_shape=X_train[0].shape))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(32,activation = 'relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1,activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 64)                6464      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 8,577\n",
      "Trainable params: 8,577\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 7500 samples\n",
      "Epoch 1/15\n",
      " - 1s - loss: 0.4085 - acc: 0.8223 - val_loss: 0.3682 - val_acc: 0.8352\n",
      "Epoch 2/15\n",
      " - 1s - loss: 0.3708 - acc: 0.8406 - val_loss: 0.3677 - val_acc: 0.8368\n",
      "Epoch 3/15\n",
      " - 1s - loss: 0.3613 - acc: 0.8452 - val_loss: 0.3607 - val_acc: 0.8404\n",
      "Epoch 4/15\n",
      " - 1s - loss: 0.3559 - acc: 0.8487 - val_loss: 0.3557 - val_acc: 0.8441\n",
      "Epoch 5/15\n",
      " - 1s - loss: 0.3522 - acc: 0.8504 - val_loss: 0.3558 - val_acc: 0.8468\n",
      "Epoch 6/15\n",
      " - 1s - loss: 0.3509 - acc: 0.8506 - val_loss: 0.3579 - val_acc: 0.8445\n",
      "Epoch 7/15\n",
      " - 1s - loss: 0.3475 - acc: 0.8513 - val_loss: 0.3534 - val_acc: 0.8480\n",
      "Epoch 8/15\n",
      " - 1s - loss: 0.3430 - acc: 0.8546 - val_loss: 0.3546 - val_acc: 0.8457\n",
      "Epoch 9/15\n",
      " - 1s - loss: 0.3431 - acc: 0.8536 - val_loss: 0.3492 - val_acc: 0.8469\n",
      "Epoch 10/15\n",
      " - 1s - loss: 0.3408 - acc: 0.8567 - val_loss: 0.3523 - val_acc: 0.8451\n",
      "Epoch 11/15\n",
      " - 1s - loss: 0.3387 - acc: 0.8569 - val_loss: 0.3575 - val_acc: 0.8463\n",
      "Epoch 12/15\n",
      " - 1s - loss: 0.3373 - acc: 0.8584 - val_loss: 0.3510 - val_acc: 0.8469\n",
      "Epoch 13/15\n",
      " - 1s - loss: 0.3339 - acc: 0.8579 - val_loss: 0.3531 - val_acc: 0.8456\n",
      "Epoch 14/15\n",
      " - 1s - loss: 0.3320 - acc: 0.8597 - val_loss: 0.3533 - val_acc: 0.8440\n",
      "Epoch 15/15\n",
      " - 1s - loss: 0.3323 - acc: 0.8588 - val_loss: 0.3502 - val_acc: 0.8492\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0e2ce11860>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train,validation_data = (X_val,y_val), epochs=15, batch_size=32, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
